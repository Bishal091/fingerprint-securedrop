{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Setup\n",
    "redshiftzero, November 29, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some CSVs to populate the database on the dev VM\n",
    "\n",
    "We want to have the PostgreSQL development VM be populated with some test data such that we can run the feature generation and machine learning codes without having to wait for a crawl to proceed or connect to the real database (of course one _can_ do either of these things if they wish). Right now the unit tests populate the test database with some a minimal amount of data and remove it after the execution of the tests but we also want the dev database to be populated with a more realistic amount of data during provisioning of the development VM. This notebook shows how this test data was generated from real data collected by our crawlers and stored in the production database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "with open(os.environ[\"PGPASS\"], \"rb\") as f:\n",
    "    content = f.readline().decode(\"utf-8\").replace(\"\\n\", \"\").split(\":\")\n",
    "\n",
    "engine = create_engine(\"postgresql://{user}:{passwd}@{host}/{db}\".format(user=content[3],\n",
    "                                                                         passwd=content[4],\n",
    "                                                                         host=content[0],\n",
    "                                                                         db=content[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frontpage_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_examples = pd.read_sql(\"SELECT * FROM raw.frontpage_examples\", con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_example_data = df_examples[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_example_data.to_csv('frontpage_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_crawls = test_example_data.crawlid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crawls_select_str = ', '.join([str(x) for x in unique_crawls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_crawls = pd.read_sql(\"SELECT * FROM raw.crawls WHERE crawlid IN ({})\".format(crawls_select_str), con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove VPS related info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_crawls['ip'] = '127.0.0.1'\n",
    "df_crawls['kernel_version'] = '1.2.3-4-generic'\n",
    "df_crawls['os'] = 'Linux'\n",
    "df_crawls['entry_node'] = '1A2B3C4D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_crawls.to_csv('crawls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### onion services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_onion_services = test_example_data.hsid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onions_select_str = ', '.join([str(x) for x in unique_onion_services])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_hs = pd.read_sql(\"SELECT * FROM raw.hs_history WHERE hsid IN ({})\".format(onions_select_str), con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably unnecessary, but replace each `hs_url` with a random (fake and invalid) address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_file = \"/usr/share/dict/words\"\n",
    "WORDS = open(word_file).read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = random.choice(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_hs['hs_url'] = df_hs['hs_url'].map(lambda x: 'http://{}1234.onion'.format(random.choice(WORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_hs.to_csv('hs_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frontpage_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the trace cells for the examples in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples_select_str = ', '.join([str(x) for x in test_example_data.exampleid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cells = pd.read_sql(\"SELECT * FROM raw.frontpage_traces WHERE exampleid IN ({})\".format(examples_select_str), con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cells.to_csv('frontpage_traces.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a nice merged version for others to play with\n",
    "\n",
    "Others who don't want to do a bunch of joins might want to play with this data, so let's construct a merged version of three of the above tables (excluding the crawls table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_examples_w_hs_info = pd.merge(test_example_data, df_hs, on='hsid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_examples_and_cells = pd.merge(df_examples_w_hs_info, df_cells, on='exampleid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_examples_and_cells.to_csv('test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
